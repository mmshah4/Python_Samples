{
 "metadata": {
  "name": "",
  "signature": "sha256:f3321521149ae1fd62160175c3f25590cd62efdddbbd23ea8e682f19766684d8"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import json\n",
      "import datetime\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Public data\n",
      "- https://data.sfgov.org\n",
      "- http://catalog.data.gov/dataset\n",
      "- https://aws.amazon.com/datasets  (Huge datasets)\n",
      "\n",
      "# For scraping\n",
      "- http://www.basketball-reference.com\n",
      "- http://www.baseball-reference.com\n",
      "- http://www.football-reference.com\n",
      "\n",
      "# Datasets on the web \n",
      "- http://static.reddit.com/RedditShortDemoSurvey-1.csv (Reddit user survey)\n",
      "- https://extxfer.sfdph.org/food/\n"
     ]
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Reading a web csv into pandas"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from the web\n",
      "#https://data.sfgov.org/Health-and-Social-Services/Restaurant-Scores/stya-26eb\n",
      "resturants = pd.read_csv('source_data/SFFoodProgram_Complete_Data/businesses_plus.csv')\n",
      "inspections = pd.read_csv('source_data/SFFoodProgram_Complete_Data/inspections_plus.csv')\n",
      "violations = pd.read_csv('source_data/SFFoodProgram_Complete_Data/violations_plus.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tmp = pd.merge(resturants, inspections, how='inner', on='business_id')\n",
      "tmp.head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Class exercise - merge the violations table into the dataframe we just created - call it rest_data\n",
      "#Hint, example the tmp and the violations table - a proper join is more than one column"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Clean the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rest_data.describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Longitude / Latitude"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Class: Drop resturants where the longitude latitidue is undefined (nan)\n",
      "#testing for null - pd.isnull or np.isnan"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Date column fixing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Just a fyi - make dates the correct datatype\n",
      "print \"Date columns datatype: {}\".format(rest_data.date.dtypes)\n",
      "\n",
      "def convert_date(row):\n",
      "    try:\n",
      "        date = datetime.datetime.strptime(row['date'], \"%Y%M%d\")\n",
      "    except:\n",
      "        date = ''\n",
      "    return date\n",
      "\n",
      "#I would like dates to be treated as dates\n",
      "rest_data['date'] = rest_data['date'].astype('str')\n",
      "rest_data['inspection_date'] = rest_data.apply(convert_date, axis='columns')\n",
      "print \"Date columns datatype: {}\".format(rest_data.inspection_date.dtypes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Zip code cleaning"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rest_data.postal_code.unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Class exercise - drop the records with a nan zip code\n",
      "nan_zips = pd.isnull(rest_data.postal_code)\n",
      "rest_data = rest_data[~(nan_zips)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Class exercise - drop records with weird zip codes - i.e. 941033148\n",
      "#Hint - dataframe.column.isin - is a useful method"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rest_data.postal_code.unique()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Remove zipcode with less than 100 resturants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rest_data.postal_code.value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Unpack this step by step\n",
      "zip_mean_counts = rest_data[['postal_code','Score']].groupby('postal_code').aggregate([np.mean, len]).sort([('Score','mean')])\n",
      "qualifying_zips = np.array([x for x in zip_mean_counts[('Score','len')] > 100])\n",
      "zip_code_list = zip_mean_counts[qualifying_zips].index"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Explore the dataset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#What is the range of scores?\n",
      "rest_data['Score'].describe()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Class exercise - plot a density plot or historgram showing the distribution of scores"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "https://www.sfdph.org/dph/EH/Food/score/default.asp"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(10,6))\n",
      "ax = fig.add_subplot(1,1,1)\n",
      "sns.set_style('white')\n",
      "\n",
      "ax.set_title('SF Sanitation Score Distribution')\n",
      "ax.set_xlabel('Score', size=24)\n",
      "ax.set_xlim([20, 100])\n",
      "\n",
      "#Clean up the chart\n",
      "#sns.despine(left=True, bottom=True)\n",
      "#ax.set_yticklabels([])\n",
      "\n",
      "ax.tick_params(axis='both', which='major', labelsize=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "The most unsanitary zip codes in SF"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#This command does a group by zip code, then aggregates values, then a sort\n",
      "rest_data[['postal_code','Score']].groupby('postal_code').aggregate([np.mean, np.min, np.max, len]).sort([('Score','mean')])\n",
      "#[rest_data.postal_code.isin(zip_code_list)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from IPython.display import Image\n",
      "Image(filename='source_data/sf_zip_codes.jpg')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "zip_to_neighborhood = {'94102':'Hayes Valley/Tenderloin','94103':'South of Market','94107':'Potrero Hill',\n",
      "                       '94108':'Chinatown', '94109':'Polk/Russian Hill (Nob Hill)', '94110':'Inner Mission/Bernal Heights', '94104': 'Financial District', '94105': 'South Park',\n",
      "                       '94111':'Embarcadero', '94112':'Ingelside-Excelsior/Crocker-Amazon', '94114':'Castro/Noe Valley', '94115':'Western Addition/Japantown',\n",
      "                       '94116':'Parkside/Forest Hill', '94117':'Haight-Ashbury', '94118':'Inner Richmond', '94121':'Outer Richmond',\n",
      "                       '94122':'Sunset', '94123':'Marina', '94124':'Bayview-Hunters Point', '94127':'St. Francis Wood',\n",
      "                       '94131':'Twin Peaks-Glen Park', '94132':'Lake Merced', '94133':'North Beach/Chinatown', '94134':'Visitacion Valley'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(20,10))\n",
      "ax = fig.add_subplot(1,1,1)\n",
      "sns.set_style('whitegrid')\n",
      "\n",
      "sanitation_scores = []\n",
      "for zip_code in zip_code_list:\n",
      "    region = rest_data.postal_code == zip_code\n",
      "    count = rest_data.postal_code[region].count()\n",
      "    if count > 100:\n",
      "        sanitation_scores.append(rest_data.Score[region].values)\n",
      "\n",
      "sns.boxplot(sanitation_scores, color='#8e44ad', alpha=0.5)\n",
      "ax.set_ylabel('Score', size=24)\n",
      "ax.set_xticklabels([zip_to_neighborhood[str(x)] for x in zip_code_list], \n",
      "                   fontsize=16, rotation=90)\n",
      "ax.tick_params(axis='both', which='major', labelsize=16)\n",
      "ax.set_title('Resturant santiation scores by zip', size=32)\n",
      "ax.set_ylim([25,101])\n",
      "print"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Make a summary table containing resturants, times inspected and mean score"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Unpack this\n",
      "mean_score_data = rest_data[['name','date','Score']].drop_duplicates()\n",
      "resturant_score = mean_score_data[['name','Score']].groupby('name').aggregate([np.mean, len])\n",
      "resturant_score.columns = resturant_score.columns.get_level_values(1)\n",
      "resturant_score.reset_index(inplace=True)\n",
      "resturant_score.rename(columns={'mean':'mean score', 'len': 'times inspected'}, inplace=True)\n",
      "resturant_score.head()\n",
      "\n",
      "#Save this to a csv file"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What were the top 10 worst resturants"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "resturant_score.sort('mean score').head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Save some lists for later\n",
      "worst_100 = resturant_score.sort('mean score')['name'][:100]\n",
      "best_100 = resturant_score.sort('mean score')['name'][-100:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "What were the voilations for the worst resturant?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rest_data.description[rest_data.name == \"Imperial Palace\"].value_counts()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Search with python string methods inside a column\n",
      "rest_data[(rest_data.name.isin(worst_100)) & (rest_data.description.str.contains('vermin') > 0)].name.value_counts().head(10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Display the data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pygamps package is installed in labs/packages\n",
      "#pip install -e packages/pygmaps-0.1.1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pygmaps \n",
      "from IPython.display import HTML"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "A closer look at longitude and latitude"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(figsize=(20,8))\n",
      "ax = fig.add_subplot(1,2,1)\n",
      "sns.kdeplot(rest_data.latitude, shade=True)\n",
      "ax.set_title('Latitude', size=32)\n",
      "ax.tick_params(axis='both', which='major', labelsize=16)\n",
      "\n",
      "ax = fig.add_subplot(1,2,2)\n",
      "sns.kdeplot(rest_data.longitude, shade=True, vertical=True)\n",
      "ax.set_title('Longitude', size=32)\n",
      "ax.tick_params(axis='both', which='major', labelsize=16)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Lets get more realistic boundaries"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "latitudes = rest_data.latitude[~np.isnan(rest_data.latitude)]\n",
      "longitudes = rest_data.longitude[~np.isnan(rest_data.longitude)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Percentile function - takes the value at the given percentile\n",
      "min_lat, max_lat = np.percentile(latitudes, 1), np.percentile(latitudes, 99)\n",
      "min_long, max_long = np.percentile(longitudes, 1), np.percentile(longitudes, 99)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mymap = pygmaps.maps((max_lat + min_lat) / 2, (max_long + min_long) / 2, 13)\n",
      "\n",
      "#Plot all the worst resturants \n",
      "for lat, lon in rest_data[['latitude','longitude']][rest_data.name.isin(worst_100)].drop_duplicates().values:\n",
      "    mymap.addpoint(lat, lon, '#e74c3c')\n",
      "\n",
      "#Plot all the best resturants\n",
      "for lat, lon in rest_data[['latitude','longitude']][rest_data.name.isin(best_100)].drop_duplicates().values:\n",
      "    mymap.addpoint(lat, lon, '#2ecc71')\n",
      "\n",
      "mymap.draw('resturant_plot.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML('<iframe src=resturant_plot.html width=1000 height=650></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Plot vermin\n",
      "mymap = pygmaps.maps((max_lat + min_lat) / 2, (max_long + min_long) / 2, 13)\n",
      "\n",
      "for lat, lon in rest_data[['latitude','longitude']][(rest_data.description == \"High risk vermin infestation\")].drop_duplicates().values:\n",
      "    mymap.addpoint(lat, lon, '#e74c3c')\n",
      "\n",
      "mymap.draw('vermin.html')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "HTML('<iframe src=vermin.html width=1000 height=650></iframe>')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}